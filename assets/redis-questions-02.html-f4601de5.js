import{_ as t}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as l,c as r,a as s,d as a,b as n,e as i}from"./app-8a5cd404.js";const p={},d=i(`<h2 id="redis-事务" tabindex="-1"><a class="header-anchor" href="#redis-事务" aria-hidden="true">#</a> Redis 事务</h2><h3 id="什么是-redis-事务" tabindex="-1"><a class="header-anchor" href="#什么是-redis-事务" aria-hidden="true">#</a> 什么是 Redis 事务？</h3><p>你可以将 Redis 中的事务理解为：<strong>Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。</strong></p><p>Redis 事务实际开发中使用的非常少，功能比较鸡肋，不要将其和我们平时理解的关系型数据库的事务混淆了。</p><p>除了不满足原子性和持久性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。明明一次批量执行多个命令就可以了，这种操作实在是看不懂。</p><p>因此，Redis 事务是不建议在日常开发中使用的。</p><h3 id="如何使用-redis-事务" tabindex="-1"><a class="header-anchor" href="#如何使用-redis-事务" aria-hidden="true">#</a> 如何使用 Redis 事务？</h3><p>Redis 可以通过 <strong><code>MULTI</code>，<code>EXEC</code>，<code>DISCARD</code> 和 <code>WATCH</code></strong> 等命令来实现事务(Transaction)功能。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token operator">&gt;</span> MULTI
OK
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide&quot;</span>
QUEUED
<span class="token operator">&gt;</span> GET PROJECT
QUEUED
<span class="token operator">&gt;</span> EXEC
<span class="token number">1</span><span class="token punctuation">)</span> OK
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">&quot;JavaGuide&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,9),c={href:"https://redis.io/commands/multi",target:"_blank",rel:"noopener noreferrer"},u=s("code",null,"MULTI",-1),h={href:"https://redis.io/commands/exec",target:"_blank",rel:"noopener noreferrer"},m=s("code",null,"EXEC",-1),k=s("p",null,"这个过程是这样的：",-1),b=s("ol",null,[s("li",null,[n("开始事务（"),s("code",null,"MULTI"),n("）；")]),s("li",null,"命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)；"),s("li",null,[n("执行事务("),s("code",null,"EXEC"),n(")。")])],-1),g={href:"https://redis.io/commands/discard",target:"_blank",rel:"noopener noreferrer"},v=s("code",null,"DISCARD",-1),y=i(`<div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token operator">&gt;</span> MULTI
OK
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide&quot;</span>
QUEUED
<span class="token operator">&gt;</span> GET PROJECT
QUEUED
<span class="token operator">&gt;</span> DISCARD
OK
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),f={href:"https://redis.io/commands/watch",target:"_blank",rel:"noopener noreferrer"},R=s("code",null,"WATCH",-1),_=s("code",null,"EXEC",-1),E=s("code",null,"WATCH",-1),x=s("strong",null,"其他客户端/Session",-1),T=i(`<div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 客户端 1</span>
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;RustGuide&quot;</span>
OK
<span class="token operator">&gt;</span> WATCH PROJECT
OK
<span class="token operator">&gt;</span> MULTI
OK
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide&quot;</span>
QUEUED

<span class="token comment"># 客户端 2</span>
<span class="token comment"># 在客户端 1 执行 EXEC 命令提交事务之前修改 PROJECT 的值</span>
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;GoGuide&quot;</span>

<span class="token comment"># 客户端 1</span>
<span class="token comment"># 修改失败，因为 PROJECT 的值被客户端2修改了</span>
<span class="token operator">&gt;</span> EXEC
<span class="token punctuation">(</span>nil<span class="token punctuation">)</span>
<span class="token operator">&gt;</span> GET PROJECT
<span class="token string">&quot;GoGuide&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),O=s("strong",null,"WATCH",-1),q=s("strong",null,"事务",-1),S=s("strong",null,"WATCH",-1),C={href:"https://github.com/Snailclimb/JavaGuide/issues/1714",target:"_blank",rel:"noopener noreferrer"},w=i(`<p>事务内部修改 WATCH 监视的 Key：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide&quot;</span>
OK
<span class="token operator">&gt;</span> WATCH PROJECT
OK
<span class="token operator">&gt;</span> MULTI
OK
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide1&quot;</span>
QUEUED
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide2&quot;</span>
QUEUED
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide3&quot;</span>
QUEUED
<span class="token operator">&gt;</span> EXEC
<span class="token number">1</span><span class="token punctuation">)</span> OK
<span class="token number">2</span><span class="token punctuation">)</span> OK
<span class="token number">3</span><span class="token punctuation">)</span> OK
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> GET PROJECT
<span class="token string">&quot;JavaGuide3&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>事务外部修改 WATCH 监视的 Key：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide&quot;</span>
OK
<span class="token operator">&gt;</span> WATCH PROJECT
OK
<span class="token operator">&gt;</span> SET PROJECT <span class="token string">&quot;JavaGuide2&quot;</span>
OK
<span class="token operator">&gt;</span> MULTI
OK
<span class="token operator">&gt;</span> GET <span class="token environment constant">USER</span>
QUEUED
<span class="token operator">&gt;</span> EXEC
<span class="token punctuation">(</span>nil<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),L={href:"https://redis.io/topics/transactions",target:"_blank",rel:"noopener noreferrer"},G=i('<figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-transactions.png" alt="Redis 事务" tabindex="0" loading="lazy"><figcaption>Redis 事务</figcaption></figure><h3 id="redis-事务支持原子性吗" tabindex="-1"><a class="header-anchor" href="#redis-事务支持原子性吗" aria-hidden="true">#</a> Redis 事务支持原子性吗？</h3><p>Redis 的事务和我们平时理解的关系型数据库的事务不同。我们知道事务具有四大特性：<strong>1. 原子性</strong>，<strong>2. 隔离性</strong>，<strong>3. 持久性</strong>，<strong>4. 一致性</strong>。</p><ol><li><strong>原子性（Atomicity）：</strong> 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li><li><strong>隔离性（Isolation）：</strong> 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li><li><strong>持久性（Durability）：</strong> 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li><li><strong>一致性（Consistency）：</strong> 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；</li></ol><p>Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的。</p><p>Redis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。</p><figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-rollback.png" alt="Redis 为什么不支持回滚" tabindex="0" loading="lazy"><figcaption>Redis 为什么不支持回滚</figcaption></figure><p><strong>相关 issue</strong> :</p>',8),N={href:"https://github.com/Snailclimb/JavaGuide/issues/452",target:"_blank",rel:"noopener noreferrer"},A={href:"https://github.com/Snailclimb/JavaGuide/issues/491",target:"_blank",rel:"noopener noreferrer"},j=i(`<h3 id="redis-事务支持持久性吗" tabindex="-1"><a class="header-anchor" href="#redis-事务支持持久性吗" aria-hidden="true">#</a> Redis 事务支持持久性吗？</h3><p>Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持 3 种持久化方式:</p><ul><li>快照（snapshotting，RDB）</li><li>只追加文件（append-only file, AOF）</li><li>RDB 和 AOF 的混合持久化(Redis 4.0 新增)</li></ul><p>与 RDB 持久化相比，AOF 持久化的实时性更好。在 Redis 的配置文件中存在三种不同的 AOF 持久化方式（ <code>fsync</code>策略），它们分别是：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>appendfsync always    <span class="token comment">#每次有数据修改发生时都会调用fsync函数同步AOF文件,fsync完成后线程返回,这样会严重降低Redis的速度</span>
appendfsync everysec  <span class="token comment">#每秒钟调用fsync函数同步一次AOF文件</span>
appendfsync no        <span class="token comment">#让操作系统决定何时进行同步，一般为30秒一次</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>AOF 持久化的<code>fsync</code>策略为 no、everysec 时都会存在数据丢失的情况 。always 下可以基本是可以满足持久性要求的，但性能太差，实际开发过程中不会使用。</p><p>因此，Redis 事务的持久性也是没办法保证的。</p><h3 id="如何解决-redis-事务的缺陷" tabindex="-1"><a class="header-anchor" href="#如何解决-redis-事务的缺陷" aria-hidden="true">#</a> 如何解决 Redis 事务的缺陷？</h3><p>Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。</p><p>一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。</p><p>不过，如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果。因此， <strong>严格来说的话，通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的。</strong></p><p>如果想要让 Lua 脚本中的命令全部执行，必须保证语句语法和命令都是对的。</p>`,12),K={href:"https://redis.io/docs/manual/programmability/functions-intro/",target:"_blank",rel:"noopener noreferrer"},I=s("h2",{id:"redis-性能优化-重要",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#redis-性能优化-重要","aria-hidden":"true"},"#"),n(" Redis 性能优化（重要）")],-1),U=s("p",null,"除了下面介绍的内容之外，再推荐两篇不错的文章：",-1),J={href:"https://mp.weixin.qq.com/s/nNEuYw0NlYGhuKKKKoWfcQ",target:"_blank",rel:"noopener noreferrer"},M={href:"https://javaguide.cn/database/redis/redis-common-blocking-problems-summary.html",target:"_blank",rel:"noopener noreferrer"},D=i('<h3 id="使用批量操作减少网络传输" tabindex="-1"><a class="header-anchor" href="#使用批量操作减少网络传输" aria-hidden="true">#</a> 使用批量操作减少网络传输</h3><p>一个 Redis 命令的执行可以简化为以下 4 步：</p><ol><li>发送命令</li><li>命令排队</li><li>命令执行</li><li>返回结果</li></ol><p>其中，第 1 步和第 4 步耗费时间之和称为 <strong>Round Trip Time (RTT,往返时间)</strong> ，也就是数据在网络上传输的时间。</p><p>使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少 RTT。</p>',5),P=s("code",null,"read()",-1),z=s("code",null,"write()",-1),B={href:"https://redis.io/docs/manual/pipelining/",target:"_blank",rel:"noopener noreferrer"},F=i('<h4 id="原生批量操作命令" tabindex="-1"><a class="header-anchor" href="#原生批量操作命令" aria-hidden="true">#</a> 原生批量操作命令</h4><p>Redis 中有一些原生支持批量操作的命令，比如：</p><ul><li><code>MGET</code>(获取一个或多个指定 key 的值)、<code>MSET</code>(设置一个或多个指定 key 的值)、</li><li><code>HMGET</code>(获取指定哈希表中一个或者多个指定字段的值)、<code>HMSET</code>(同时将一个或多个 field-value 对设置到指定哈希表中)、</li><li><code>SADD</code>（向指定集合添加一个或多个元素）</li><li>......</li></ul><p>不过，在 Redis 官方提供的分片集群解决方案 Redis Cluster 下，使用这些原生批量操作命令可能会存在一些小问题需要解决。就比如说 <code>MGET</code> 无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上，<code>MGET</code>可能还是需要多次网络传输，原子操作也无法保证了。不过，相较于非批量操作，还是可以节省不少网络传输次数。</p><p>整个步骤的简化版如下（通常由 Redis 客户端实现，无需我们自己再手动实现）：</p><ol><li>找到 key 对应的所有 hash slot；</li><li>分别向对应的 Redis 节点发起 <code>MGET</code> 请求获取数据；</li><li>等待所有请求执行结束，重新组装结果数据，保持跟入参 key 的顺序一致，然后返回结果。</li></ol><p>如果想要解决这个多次网络传输的问题，比较常用的办法是自己维护 key 与 slot 的关系。不过这样不太灵活，虽然带来了性能提升，但同样让系统复杂性提升。</p>',7),W=s("p",null,[n("Redis Cluster 并没有使用一致性哈希，采用的是 "),s("strong",null,"哈希槽分区"),n(" ，每一个键值对都属于一个 "),s("strong",null,"hash slot"),n("（哈希槽） 。当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标 Redis 节点。")],-1),H={href:"https://javaguide.cn/database/redis/redis-cluster.html",target:"_blank",rel:"noopener noreferrer"},Q=i(`<h4 id="pipeline" tabindex="-1"><a class="header-anchor" href="#pipeline" aria-hidden="true">#</a> pipeline</h4><p>对于不支持批量操作的命令，我们可以利用 <strong>pipeline（流水线)</strong> 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输。不过，需要注意控制一次批量操作的 <strong>元素个数</strong>(例如 500 以内，实际也和元素字节数有关)，避免网络传输的数据量过大。</p><p>与<code>MGET</code>、<code>MSET</code>等原生批量操作命令一样，pipeline 同样在 Redis Cluster 上使用会存在一些小问题。原因类似，无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上。如果想要使用的话，客户端需要自己维护 key 与 slot 的关系。</p><p>原生批量操作命令和 pipeline 的是有区别的，使用的时候需要注意：</p><ul><li>原生批量操作命令是原子操作，pipeline 是非原子操作。</li><li>pipeline 可以打包不同的命令，原生批量操作命令不可以。</li><li>原生批量操作命令是 Redis 服务端支持实现的，而 pipeline 需要服务端和客户端的共同实现。</li></ul><p>顺带补充一下 pipeline 和 Redis 事务的对比：</p><ul><li>事务是原子操作，pipeline 是非原子操作。两个不同的事务不会同时运行，而 pipeline 可以同时以交错方式执行。</li><li>Redis 事务中每个命令都需要发送到服务端，而 Pipeline 只需要发送一次，请求次数更少。</li></ul><blockquote><p>事务可以看作是一个原子操作，但其实并不满足原子性。当我们提到 Redis 中的原子操作时，主要指的是这个操作（比如事务、Lua 脚本）不会被其他操作（比如其他事务、Lua 脚本）打扰，并不能完全保证这个操作中的所有写命令要么都执行要么都不执行。这主要也是因为 Redis 是不支持回滚操作。</p></blockquote><figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-pipeline-vs-transaction.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>另外，pipeline 不适用于执行顺序有依赖关系的一批命令。就比如说，你需要将前一个命令的结果给后续的命令使用，pipeline 就没办法满足你的需求了。对于这种需求，我们可以使用 <strong>Lua 脚本</strong> 。</p><h4 id="lua-脚本" tabindex="-1"><a class="header-anchor" href="#lua-脚本" aria-hidden="true">#</a> Lua 脚本</h4><p>Lua 脚本同样支持批量操作多条命令。一段 Lua 脚本可以视作一条命令执行，可以看作是 <strong>原子操作</strong> 。也就是说，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。</p><p>并且，Lua 脚本中支持一些简单的逻辑处理比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。</p><p>不过， Lua 脚本依然存在下面这些缺陷：</p><ul><li>如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。</li><li>Redis Cluster 下 Lua 脚本的原子操作也无法保证了，原因同样是无法保证所有的 key 都在同一个 <strong>hash slot</strong>（哈希槽）上。</li></ul><h3 id="大量-key-集中过期问题" tabindex="-1"><a class="header-anchor" href="#大量-key-集中过期问题" aria-hidden="true">#</a> 大量 key 集中过期问题</h3><p>我在前面提到过：对于过期 key，Redis 采用的是 <strong>定期删除+惰性/懒汉式删除</strong> 策略。</p><p>定期删除执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。</p><p><strong>如何解决呢？</strong> 下面是两种常见的方法：</p><ol><li>给 key 设置随机过期时间。</li><li>开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。</li></ol><p>个人建议不管是否开启 lazy-free，我们都尽量给 key 设置随机过期时间。</p><h3 id="redis-bigkey-大-key" tabindex="-1"><a class="header-anchor" href="#redis-bigkey-大-key" aria-hidden="true">#</a> Redis bigkey（大 Key）</h3><h4 id="什么是-bigkey" tabindex="-1"><a class="header-anchor" href="#什么是-bigkey" aria-hidden="true">#</a> 什么是 bigkey？</h4><p>简单来说，如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。具体多大才算大呢？有一个不是特别精确的参考标准：string 类型的 value 超过 10 kb，复合类型的 value 包含的元素超过 5000 个（对于复合类型的 value 来说，不一定包含的元素越多，占用的内存就越多）。</p><h4 id="bigkey-有什么危害" tabindex="-1"><a class="header-anchor" href="#bigkey-有什么危害" aria-hidden="true">#</a> bigkey 有什么危害？</h4><p>bigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响。因此，我们应该尽量避免 Redis 中存在 bigkey。</p><h4 id="如何发现-bigkey" tabindex="-1"><a class="header-anchor" href="#如何发现-bigkey" aria-hidden="true">#</a> 如何发现 bigkey？</h4><p><strong>1、使用 Redis 自带的 <code>--bigkeys</code> 参数来查找。</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># redis-cli -p 6379 --bigkeys</span>

<span class="token comment"># Scanning the entire keyspace to find biggest keys as well as</span>
<span class="token comment"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span>
<span class="token comment"># per 100 SCAN commands (not usually needed).</span>

<span class="token punctuation">[</span>00.00%<span class="token punctuation">]</span> Biggest string found so far <span class="token string">&#39;&quot;ballcat:oauth:refresh_auth:f6cdb384-9a9d-4f2f-af01-dc3f28057c20&quot;&#39;</span> with <span class="token number">4437</span> bytes
<span class="token punctuation">[</span>00.00%<span class="token punctuation">]</span> Biggest list   found so far <span class="token string">&#39;&quot;my-list&quot;&#39;</span> with <span class="token number">17</span> items

-------- summary -------

Sampled <span class="token number">5</span> keys <span class="token keyword">in</span> the keyspace<span class="token operator">!</span>
Total key length <span class="token keyword">in</span> bytes is <span class="token number">264</span> <span class="token punctuation">(</span>avg len <span class="token number">52.80</span><span class="token punctuation">)</span>

Biggest   list found <span class="token string">&#39;&quot;my-list&quot;&#39;</span> has <span class="token number">17</span> items
Biggest string found <span class="token string">&#39;&quot;ballcat:oauth:refresh_auth:f6cdb384-9a9d-4f2f-af01-dc3f28057c20&quot;&#39;</span> has <span class="token number">4437</span> bytes

<span class="token number">1</span> lists with <span class="token number">17</span> items <span class="token punctuation">(</span><span class="token number">20.00</span>% of keys, avg size <span class="token number">17.00</span><span class="token punctuation">)</span>
<span class="token number">0</span> hashs with <span class="token number">0</span> fields <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span><span class="token punctuation">)</span>
<span class="token number">4</span> strings with <span class="token number">4831</span> bytes <span class="token punctuation">(</span><span class="token number">80.00</span>% of keys, avg size <span class="token number">1207.75</span><span class="token punctuation">)</span>
<span class="token number">0</span> streams with <span class="token number">0</span> entries <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span><span class="token punctuation">)</span>
<span class="token number">0</span> sets with <span class="token number">0</span> members <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span><span class="token punctuation">)</span>
<span class="token number">0</span> zsets with <span class="token number">0</span> members <span class="token punctuation">(</span>00.00% of keys, avg size <span class="token number">0.00</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从这个命令的运行结果，我们可以看出：这个命令会扫描(Scan) Redis 中的所有 key ，会对 Redis 的性能有一点影响。并且，这种方式只能找出每种数据结构 top 1 bigkey（占用内存最大的 string 数据类型，包含元素最多的复合数据类型）。然而，一个 key 的元素多并不代表占用内存也多，需要我们根据具体的业务情况来进一步判断。</p><p>在线上执行该命令时，为了降低对 Redis 的影响，需要指定 <code>-i</code> 参数控制扫描的频率。<code>redis-cli -p 6379 --bigkeys -i 3</code> 表示扫描过程中每次扫描后休息的时间间隔为 3 秒。</p><p><strong>2、借助开源工具分析 RDB 文件。</strong></p><p>通过分析 RDB 文件来找出 big key。这种方案的前提是你的 Redis 采用的是 RDB 持久化。</p><p>网上有现成的代码/工具可以直接拿来使用：</p>`,34),Y={href:"https://github.com/sripathikrishnan/redis-rdb-tools",target:"_blank",rel:"noopener noreferrer"},V={href:"https://github.com/weiyanwei412/rdb_bigkeys",target:"_blank",rel:"noopener noreferrer"},X=s("p",null,[s("strong",null,"3、借助公有云的 Redis 分析服务。")],-1),Z=s("p",null,"如果你用的是公有云的 Redis 服务的话，可以看看其是否提供了 key 分析功能（一般都提供了）。",-1),$={href:"https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature",target:"_blank",rel:"noopener noreferrer"},ss=i(`<figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/aliyun-key-analysis.png" alt="阿里云Key分析" tabindex="0" loading="lazy"><figcaption>阿里云Key分析</figcaption></figure><h4 id="如何处理-bigkey" tabindex="-1"><a class="header-anchor" href="#如何处理-bigkey" aria-hidden="true">#</a> 如何处理 bigkey？</h4><p>bigkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）：</p><ul><li><strong>分割 bigkey</strong>：将一个 bigkey 分割为多个小 key。这种方式需要修改业务层的代码，一般不推荐这样做。</li><li><strong>手动清理</strong>：Redis 4.0+ 可以使用 <code>UNLINK</code> 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 <code>SCAN</code> 命令结合 <code>DEL</code> 命令来分批次删除。</li><li><strong>采用合适的数据结构</strong>：比如使用 HyperLogLog 统计页面 UV。</li><li><strong>开启 lazy-free（惰性删除/延迟释放）</strong> ：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。</li></ul><h3 id="redis-hotkey-热-key" tabindex="-1"><a class="header-anchor" href="#redis-hotkey-热-key" aria-hidden="true">#</a> Redis hotkey（热 Key）</h3><h4 id="什么是-hotkey" tabindex="-1"><a class="header-anchor" href="#什么是-hotkey" aria-hidden="true">#</a> 什么是 hotkey？</h4><p>简单来说，如果一个 key 的访问次数比较多且明显多于其他 key 的话，那这个 key 就可以看作是 hotkey。例如在 Redis 实例的每秒处理请求达到 5000 次，而其中某个 key 的每秒访问量就高达 2000 次，那这个 key 就可以看作是 hotkey。</p><p>hotkey 出现的原因主要是某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品。</p><h4 id="hotkey-有什么危害" tabindex="-1"><a class="header-anchor" href="#hotkey-有什么危害" aria-hidden="true">#</a> hotkey 有什么危害？</h4><p>处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。</p><p>因此，hotkey 很可能成为系统性能的瓶颈点，需要单独对其进行优化，以确保系统的高可用性和稳定性。</p><h4 id="如何发现-hotkey" tabindex="-1"><a class="header-anchor" href="#如何发现-hotkey" aria-hidden="true">#</a> 如何发现 hotkey？</h4><p><strong>1、使用 Redis 自带的 <code>--hotkeys</code> 参数来查找。</strong></p><p>Redis 4.0.3 版本中新增了 <code>hotkeys</code> 参数，该参数能够返回所有 key 的被访问次数。</p><p>使用该方案的前提条件是 Redis Server 的 <code>maxmemory-policy</code> 参数设置为 LFU 算法，不然就会出现如下所示的错误。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># redis-cli -p 6379 --hotkeys</span>

<span class="token comment"># Scanning the entire keyspace to find hot keys as well as</span>
<span class="token comment"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span>
<span class="token comment"># per 100 SCAN commands (not usually needed).</span>

Error: ERR An LFU maxmemory policy is not selected, access frequency not tracked. Please note that when switching between policies at runtime LRU and LFU data will take some <span class="token function">time</span> to adjust.
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Redis 中有两种 LFU 算法：</p><ol><li><strong>volatile-lfu（least frequently used）</strong>：从已设置过期时间的数据集（<code>server.db[i].expires</code>）中挑选最不经常使用的数据淘汰。</li><li><strong>allkeys-lfu（least frequently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。</li></ol><p>以下是配置文件 <code>redis.conf</code> 中的示例：</p><div class="language-properties line-numbers-mode" data-ext="properties"><pre class="language-properties"><code><span class="token comment"># 使用 volatile-lfu 策略</span>
<span class="token key attr-name">maxmemory-policy</span> <span class="token value attr-value">volatile-lfu</span>

<span class="token comment"># 或者使用 allkeys-lfu 策略</span>
<span class="token key attr-name">maxmemory-policy</span> <span class="token value attr-value">allkeys-lfu</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>需要注意的是，<code>hotkeys</code> 参数命令也会增加 Redis 实例的 CPU 和内存消耗（全局扫描），因此需要谨慎使用。</p><p><strong>2、使用<code>MONITOR</code> 命令。</strong></p><p><code>MONITOR</code> 命令是 Redis 提供的一种实时查看 Redis 的所有操作的方式，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。</p><p>由于该命令对 Redis 性能的影响比较大，因此禁止长时间开启 <code>MONITOR</code>（生产环境中建议谨慎使用该命令）。</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code># redis<span class="token operator">-</span>cli
<span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> <span class="token constant">MONITOR</span>
<span class="token constant">OK</span>
<span class="token number">1683638260.637378</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61516</span><span class="token punctuation">]</span> <span class="token string">&quot;ping&quot;</span>
<span class="token number">1683638267.144236</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">&quot;smembers&quot;</span> <span class="token string">&quot;mySet&quot;</span>
<span class="token number">1683638268.941863</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">&quot;smembers&quot;</span> <span class="token string">&quot;mySet&quot;</span>
<span class="token number">1683638269.551671</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">&quot;smembers&quot;</span> <span class="token string">&quot;mySet&quot;</span>
<span class="token number">1683638270.646256</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61516</span><span class="token punctuation">]</span> <span class="token string">&quot;ping&quot;</span>
<span class="token number">1683638270.849551</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">&quot;smembers&quot;</span> <span class="token string">&quot;mySet&quot;</span>
<span class="token number">1683638271.926945</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">&quot;smembers&quot;</span> <span class="token string">&quot;mySet&quot;</span>
<span class="token number">1683638274.276599</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">&quot;smembers&quot;</span> <span class="token string">&quot;mySet2&quot;</span>
<span class="token number">1683638276.327234</span> <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">172.17</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">61518</span><span class="token punctuation">]</span> <span class="token string">&quot;smembers&quot;</span> <span class="token string">&quot;mySet&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在发生紧急情况时，我们可以选择在合适的时机短暂执行 <code>MONITOR</code> 命令并将输出重定向至文件，在关闭 <code>MONITOR</code> 命令后通过对文件中请求进行归类分析即可找出这段时间中的 hotkey。</p><p><strong>3、借助开源项目。</strong></p>`,27),ns={href:"https://gitee.com/jd-platform-opensource/hotkey",target:"_blank",rel:"noopener noreferrer"},es=s("figure",null,[s("img",{src:"https://oss.javaguide.cn/github/javaguide/database/redis/jd-hotkey.png",alt:"京东零售开源的 hotkey",tabindex:"0",loading:"lazy"}),s("figcaption",null,"京东零售开源的 hotkey")],-1),as=s("p",null,[s("strong",null,"4、根据业务情况提前预估。")],-1),is=s("p",null,"可以根据业务情况来预估一些 hotkey，比如参与秒杀活动的商品数据等。不过，我们无法预估所有 hotkey 的出现，比如突发的热点新闻事件等。",-1),ts=s("p",null,[s("strong",null,"5、业务代码中记录分析。")],-1),os=s("p",null,"在业务代码中添加相应的逻辑对 key 的访问情况进行记录分析。不过，这种方式会让业务代码的复杂性增加，一般也不会采用。",-1),ls=s("p",null,[s("strong",null,"6、借助公有云的 Redis 分析服务。")],-1),rs=s("p",null,"如果你用的是公有云的 Redis 服务的话，可以看看其是否提供了 key 分析功能（一般都提供了）。",-1),ps={href:"https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature",target:"_blank",rel:"noopener noreferrer"},ds=i(`<figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/aliyun-key-analysis.png" alt="阿里云Key分析" tabindex="0" loading="lazy"><figcaption>阿里云Key分析</figcaption></figure><h4 id="如何解决-hotkey" tabindex="-1"><a class="header-anchor" href="#如何解决-hotkey" aria-hidden="true">#</a> 如何解决 hotkey？</h4><p>hotkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）：</p><ul><li><strong>读写分离</strong>：主节点处理写请求，从节点处理读请求。</li><li><strong>使用 Redis Cluster</strong>：将热点数据分散存储在多个 Redis 节点上。</li><li><strong>二级缓存</strong>：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。</li></ul><p>除了这些方法之外，如果你使用的公有云的 Redis 服务话，还可以留意其提供的开箱即用的解决方案。</p><p>这里以阿里云 Redis 为例说明，它支持通过代理查询缓存功能（Proxy Query Cache）优化热点 Key 问题。</p><figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/aliyun-hotkey-proxy-query-cache.png" alt="通过阿里云的Proxy Query Cache优化热点Key问题" tabindex="0" loading="lazy"><figcaption>通过阿里云的Proxy Query Cache优化热点Key问题</figcaption></figure><h3 id="慢查询命令" tabindex="-1"><a class="header-anchor" href="#慢查询命令" aria-hidden="true">#</a> 慢查询命令</h3><h4 id="为什么会有慢查询命令" tabindex="-1"><a class="header-anchor" href="#为什么会有慢查询命令" aria-hidden="true">#</a> 为什么会有慢查询命令？</h4><p>我们知道一个 Redis 命令的执行可以简化为以下 4 步：</p><ol><li>发送命令</li><li>命令排队</li><li>命令执行</li><li>返回结果</li></ol><p>Redis 慢查询统计的是命令执行这一步骤的耗时，慢查询命令也就是那些命令执行时间较长的命令。</p><p>Redis 为什么会有慢查询命令呢？</p><p>Redis 中的大部分命令都是 O(1)时间复杂度，但也有少部分 O(n) 时间复杂度的命令，例如：</p><ul><li><code>KEYS *</code>：会返回所有符合规则的 key。</li><li><code>HGETALL</code>：会返回一个 Hash 中所有的键值对。</li><li><code>LRANGE</code>：会返回 List 中指定范围内的元素。</li><li><code>SMEMBERS</code>：返回 Set 中的所有元素。</li><li><code>SINTER</code>/<code>SUNION</code>/<code>SDIFF</code>：计算多个 Set 的交集/并集/差集。</li><li>......</li></ul><p>由于这些命令时间复杂度是 O(n)，有时候也会全表扫描，随着 n 的增大，执行耗时也会越长。不过， 这些命令并不是一定不能使用，但是需要明确 N 的值。另外，有遍历的需求可以使用 <code>HSCAN</code>、<code>SSCAN</code>、<code>ZSCAN</code> 代替。</p><p>除了这些 O(n)时间复杂度的命令可能会导致慢查询之外， 还有一些时间复杂度可能在 O(N) 以上的命令，例如：</p><ul><li><code>ZRANGE</code>/<code>ZREVRANGE</code>：返回指定 Sorted Set 中指定排名范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量， m 为返回的元素数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。</li><li><code>ZREMRANGEBYRANK</code>/<code>ZREMRANGEBYSCORE</code>：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量， m 被删除元素的数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。</li><li>......</li></ul><h4 id="如何找到慢查询命令" tabindex="-1"><a class="header-anchor" href="#如何找到慢查询命令" aria-hidden="true">#</a> 如何找到慢查询命令？</h4><p>在 <code>redis.conf</code> 文件中，我们可以使用 <code>slowlog-log-slower-than</code> 参数设置耗时命令的阈值，并使用 <code>slowlog-max-len</code> 参数设置耗时命令的最大记录条数。</p><p>当 Redis 服务器检测到执行时间超过 <code>slowlog-log-slower-than</code>阈值的命令时，就会将该命令记录在慢查询日志(slow log) 中，这点和 MySQL 记录慢查询语句类似。当慢查询日志超过设定的最大记录条数之后，Redis 会把最早的执行命令依次舍弃。</p><p>⚠️注意：由于慢查询日志会占用一定内存空间，如果设置最大记录条数过大，可能会导致内存占用过高的问题。</p><p><code>slowlog-log-slower-than</code>和<code>slowlog-max-len</code>的默认配置如下(可以自行修改)：</p><div class="language-nginx line-numbers-mode" data-ext="nginx"><pre class="language-nginx"><code><span class="token comment"># The following time is expressed in microseconds, so 1000000 is equivalent</span>
<span class="token comment"># to one second. Note that a negative number disables the slow log, while</span>
<span class="token comment"># a value of zero forces the logging of every command.</span>
slowlog-log-slower-than 10000

<span class="token comment"># There is no limit to this length. Just be aware that it will consume memory.</span>
<span class="token comment"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span>
slowlog-max-len 128
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>除了修改配置文件之外，你也可以直接通过 <code>CONFIG</code> 命令直接设置：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 命令执行耗时超过 10000 微妙（即10毫秒）就会被记录</span>
CONFIG SET slowlog-log-slower-than <span class="token number">10000</span>
<span class="token comment"># 只保留最近 128 条耗时命令</span>
CONFIG SET slowlog-max-len <span class="token number">128</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>获取慢查询日志的内容很简单，直接使用<code>SLOWLOG GET</code> 命令即可。</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">6379</span><span class="token operator">&gt;</span> <span class="token constant">SLOWLOG</span> <span class="token constant">GET</span> #慢日志查询
 <span class="token number">1</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">5</span>
   <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1684326682</span>
   <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">12000</span>
   <span class="token number">4</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">&quot;KEYS&quot;</span>
      <span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">&quot;*&quot;</span>
   <span class="token number">5</span><span class="token punctuation">)</span> <span class="token string">&quot;172.17.0.1:61152&quot;</span>
   <span class="token number">6</span><span class="token punctuation">)</span> <span class="token string">&quot;&quot;</span>
  <span class="token comment">// ...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>慢查询日志中的每个条目都由以下六个值组成：</p><ol><li>唯一渐进的日志标识符。</li><li>处理记录命令的 Unix 时间戳。</li><li>执行所需的时间量，以微秒为单位。</li><li>组成命令参数的数组。</li><li>客户端 IP 地址和端口。</li><li>客户端名称。</li></ol><p><code>SLOWLOG GET</code> 命令默认返回最近 10 条的的慢查询命令，你也自己可以指定返回的慢查询命令的数量 <code>SLOWLOG GET N</code>。</p><p>下面是其他比较常用的慢查询相关的命令：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 返回慢查询命令的数量</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> SLOWLOG LEN
<span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">128</span>
<span class="token comment"># 清空慢查询命令</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> SLOWLOG RESET
OK
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="redis-内存碎片" tabindex="-1"><a class="header-anchor" href="#redis-内存碎片" aria-hidden="true">#</a> Redis 内存碎片</h3><p><strong>相关问题</strong>：</p><ol><li>什么是内存碎片?为什么会有 Redis 内存碎片?</li><li>如何清理 Redis 内存碎片？</li></ol>`,36),cs=s("strong",null,"参考答案",-1),us={href:"https://javaguide.cn/database/redis/redis-memory-fragmentation.html",target:"_blank",rel:"noopener noreferrer"},hs=i(`<h2 id="redis-生产问题-重要" tabindex="-1"><a class="header-anchor" href="#redis-生产问题-重要" aria-hidden="true">#</a> Redis 生产问题（重要）</h2><h3 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透" aria-hidden="true">#</a> 缓存穿透</h3><h4 id="什么是缓存穿透" tabindex="-1"><a class="header-anchor" href="#什么是缓存穿透" aria-hidden="true">#</a> 什么是缓存穿透？</h4><p>缓存穿透说简单点就是大量请求的 key 是不合理的，<strong>根本不存在于缓存中，也不存在于数据库中</strong> 。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。</p><figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-cache-penetration.png" alt="缓存穿透" tabindex="0" loading="lazy"><figcaption>缓存穿透</figcaption></figure><p>举个例子：某个黑客故意制造一些非法的 key 发起大量请求，导致大量请求落到数据库，结果数据库上也没有查到对应的数据。也就是说这些请求最终都落到了数据库上，对数据库造成了巨大的压力。</p><h4 id="有哪些解决办法" tabindex="-1"><a class="header-anchor" href="#有哪些解决办法" aria-hidden="true">#</a> 有哪些解决办法？</h4><p>最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。</p><p><strong>1）缓存无效 key</strong></p><p>如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下：<code>SET key value EX 10086</code> 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。</p><p>另外，这里多说一嘴，一般情况下我们是这样设计 key 的：<code>表名:列名:主键名:主键值</code> 。</p><p>如果用 Java 代码展示的话，差不多是下面这样的：</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token class-name">Object</span> <span class="token function">getObjectInclNullById</span><span class="token punctuation">(</span><span class="token class-name">Integer</span> id<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// 从缓存中获取数据</span>
    <span class="token class-name">Object</span> cacheValue <span class="token operator">=</span> cache<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 缓存为空</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>cacheValue <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 从数据库中获取</span>
        <span class="token class-name">Object</span> storageValue <span class="token operator">=</span> storage<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 缓存空对象</span>
        cache<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> storageValue<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 如果存储数据为空，需要设置一个过期时间(300秒)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>storageValue <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">// 必须设置过期时间，否则有被攻击的风险</span>
            cache<span class="token punctuation">.</span><span class="token function">expire</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">return</span> storageValue<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">return</span> cacheValue<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>2）布隆过滤器</strong></p><p>布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。</p><p>具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。</p><p>加入布隆过滤器之后的缓存处理流程图如下。</p><figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-cache-penetration-bloom-filter.png" alt="加入布隆过滤器之后的缓存处理流程图" tabindex="0" loading="lazy"><figcaption>加入布隆过滤器之后的缓存处理流程图</figcaption></figure><p>但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是：<strong>布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。</strong></p><p><em>为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！</em></p><p>我们先来看一下，<strong>当一个元素加入布隆过滤器中的时候，会进行哪些操作：</strong></p><ol><li>使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。</li><li>根据得到的哈希值，在位数组中把对应下标的值置为 1。</li></ol><p>我们再来看一下，<strong>当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：</strong></p><ol><li>对给定元素再次进行相同的哈希计算；</li><li>得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。</li></ol><p>然后，一定会出现这样一种情况：<strong>不同的字符串可能哈希出来的位置相同。</strong> （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）</p>`,25),ms={href:"https://javaguide.cn/cs-basics/data-structure/bloom-filter/",target:"_blank",rel:"noopener noreferrer"},ks=i('<h3 id="缓存击穿" tabindex="-1"><a class="header-anchor" href="#缓存击穿" aria-hidden="true">#</a> 缓存击穿</h3><h4 id="什么是缓存击穿" tabindex="-1"><a class="header-anchor" href="#什么是缓存击穿" aria-hidden="true">#</a> 什么是缓存击穿？</h4><p>缓存击穿中，请求的 key 对应的是 <strong>热点数据</strong> ，该数据 <strong>存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）</strong> 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。</p><figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-cache-breakdown.png" alt="缓存击穿" tabindex="0" loading="lazy"><figcaption>缓存击穿</figcaption></figure><p>举个例子：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力。</p><h4 id="有哪些解决办法-1" tabindex="-1"><a class="header-anchor" href="#有哪些解决办法-1" aria-hidden="true">#</a> 有哪些解决办法？</h4><ul><li>设置热点数据永不过期或者过期时间比较长。</li><li>针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。</li><li>请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。</li></ul><h4 id="缓存穿透和缓存击穿有什么区别" tabindex="-1"><a class="header-anchor" href="#缓存穿透和缓存击穿有什么区别" aria-hidden="true">#</a> 缓存穿透和缓存击穿有什么区别？</h4><p>缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。</p><p>缓存击穿中，请求的 key 对应的是 <strong>热点数据</strong> ，该数据 <strong>存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）</strong> 。</p><h3 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩" aria-hidden="true">#</a> 缓存雪崩</h3><h4 id="什么是缓存雪崩" tabindex="-1"><a class="header-anchor" href="#什么是缓存雪崩" aria-hidden="true">#</a> 什么是缓存雪崩？</h4><p>我发现缓存雪崩这名字起的有点意思，哈哈。</p><p>实际上，缓存雪崩描述的就是这样一个简单的场景：<strong>缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。</strong> 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。</p><p>另外，缓存服务宕机也会导致缓存雪崩现象，导致所有的请求都落到了数据库上。</p><figure><img src="https://oss.javaguide.cn/github/javaguide/database/redis/redis-cache-avalanche.png" alt="缓存雪崩" tabindex="0" loading="lazy"><figcaption>缓存雪崩</figcaption></figure><p>举个例子：数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。这就导致大量的请求直接落到数据库上，对数据库造成了巨大的压力。</p><h4 id="有哪些解决办法-2" tabindex="-1"><a class="header-anchor" href="#有哪些解决办法-2" aria-hidden="true">#</a> 有哪些解决办法？</h4><p><strong>针对 Redis 服务不可用的情况：</strong></p><ol><li>采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。</li><li>限流，避免同时处理大量的请求。</li></ol><p><strong>针对热点缓存失效的情况：</strong></p><ol><li>设置不同的失效时间比如随机设置缓存的失效时间。</li><li>缓存永不失效（不太推荐，实用性太差）。</li><li>设置二级缓存。</li></ol><h4 id="缓存雪崩和缓存击穿有什么区别" tabindex="-1"><a class="header-anchor" href="#缓存雪崩和缓存击穿有什么区别" aria-hidden="true">#</a> 缓存雪崩和缓存击穿有什么区别？</h4><p>缓存雪崩和缓存击穿比较像，但缓存雪崩导致的原因是缓存中的大量或者所有数据失效，缓存击穿导致的原因主要是某个热点数据不存在与缓存中（通常是因为缓存中的那份数据已经过期）。</p><h3 id="如何保证缓存和数据库数据的一致性" tabindex="-1"><a class="header-anchor" href="#如何保证缓存和数据库数据的一致性" aria-hidden="true">#</a> 如何保证缓存和数据库数据的一致性？</h3><p>细说的话可以扯很多，但是我觉得其实没太大必要（小声 BB：很多解决方案我也没太弄明白）。我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。</p><p>下面单独对 <strong>Cache Aside Pattern（旁路缓存模式）</strong> 来聊聊。</p><p>Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。</p><p>如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：</p><ol><li><strong>缓存失效时间变短（不推荐，治标不治本）</strong>：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。</li><li><strong>增加 cache 更新重试机制（常用）</strong>：如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。</li></ol>',30),bs={href:"https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247487312&idx=1&sn=fa19566f5729d6598155b5c676eee62d&chksm=e8beb8e5dfc931f3e35655da9da0b61c79f2843101c130cf38996446975014f958a6481aacf1&scene=178&cur_album_id=1699766580538032128#rd",target:"_blank",rel:"noopener noreferrer"},gs=s("h3",{id:"哪些情况可能会导致-redis-阻塞",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#哪些情况可能会导致-redis-阻塞","aria-hidden":"true"},"#"),n(" 哪些情况可能会导致 Redis 阻塞？")],-1),vs={href:"https://javaguide.cn/database/redis/redis-common-blocking-problems-summary.html",target:"_blank",rel:"noopener noreferrer"},ys=i('<h2 id="redis-集群" tabindex="-1"><a class="header-anchor" href="#redis-集群" aria-hidden="true">#</a> Redis 集群</h2><p><strong>Redis Sentinel</strong>：</p><ol><li>什么是 Sentinel？ 有什么用？</li><li>Sentinel 如何检测节点是否下线？主观下线与客观下线的区别?</li><li>Sentinel 是如何实现故障转移的？</li><li>为什么建议部署多个 sentinel 节点（哨兵集群）？</li><li>Sentinel 如何选择出新的 master（选举机制）?</li><li>如何从 Sentinel 集群中选择出 Leader ？</li><li>Sentinel 可以防止脑裂吗？</li></ol><p><strong>Redis Cluster</strong>：</p><ol><li>为什么需要 Redis Cluster？解决了什么问题？有什么优势？</li><li>Redis Cluster 是如何分片的？</li><li>为什么 Redis Cluster 的哈希槽是 16384 个?</li><li>如何确定给定 key 的应该分布到哪个哈希槽中？</li><li>Redis Cluster 支持重新分配哈希槽吗？</li><li>Redis Cluster 扩容缩容期间可以提供服务吗？</li><li>Redis Cluster 中的节点是怎么进行通信的？</li></ol>',5),fs=s("strong",null,"参考答案",-1),Rs={href:"https://javaguide.cn/database/redis/redis-cluster.html",target:"_blank",rel:"noopener noreferrer"},_s=i('<h2 id="redis-使用规范" tabindex="-1"><a class="header-anchor" href="#redis-使用规范" aria-hidden="true">#</a> Redis 使用规范</h2><p>实际使用 Redis 的过程中，我们尽量要准守一些常见的规范，比如：</p><ol><li>使用连接池：避免频繁创建关闭客户端连接。</li><li>尽量不使用 O(n)指令，使用 O(n) 命令时要关注 n 的数量：像 <code>KEYS *</code>、<code>HGETALL</code>、<code>LRANGE</code>、<code>SMEMBERS</code>、<code>SINTER</code>/<code>SUNION</code>/<code>SDIFF</code>等 O(n) 命令并非不能使用，但是需要明确 n 的值。另外，有遍历的需求可以使用 <code>HSCAN</code>、<code>SSCAN</code>、<code>ZSCAN</code> 代替。</li><li>使用批量操作减少网络传输：原生批量操作命令（比如 <code>MGET</code>、<code>MSET</code>等等）、pipeline、Lua 脚本。</li><li>尽量不适用 Redis 事务：Redis 事务实现的功能比较鸡肋，可以使用 Lua 脚本代替。</li><li>禁止长时间开启 monitor：对性能影响比较大。</li><li>控制 key 的生命周期：避免 Redis 中存放了太多不经常被访问的数据。</li><li>......</li></ol>',3),Es={href:"https://developer.aliyun.com/article/531067",target:"_blank",rel:"noopener noreferrer"},xs=s("h2",{id:"参考",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#参考","aria-hidden":"true"},"#"),n(" 参考")],-1),Ts=s("li",null,"《Redis 开发与运维》",-1),Os=s("li",null,"《Redis 设计与实现》",-1),qs={href:"https://redis.io/docs/manual/transactions/",target:"_blank",rel:"noopener noreferrer"},Ss={href:"https://buildatscale.tech/what-is-redis-pipeline/",target:"_blank",rel:"noopener noreferrer"},Cs={href:"https://mp.weixin.qq.com/s/FPYE1B839_8Yk1-YSiW-1Q",target:"_blank",rel:"noopener noreferrer"},ws={href:"https://mp.weixin.qq.com/s/mIc6a9mfEGdaNDD3MmfFsg",target:"_blank",rel:"noopener noreferrer"};function Ls(Gs,Ns){const e=o("ExternalLinkIcon");return l(),r("div",null,[d,s("p",null,[s("a",c,[u,a(e)]),n(" 命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 "),s("a",h,[m,a(e)]),n(" 命令后，再执行所有的命令。")]),k,b,s("p",null,[n("你也可以通过 "),s("a",g,[v,a(e)]),n(" 命令取消一个事务，它会清空事务队列中保存的所有命令。")]),y,s("p",null,[n("你可以通过"),s("a",f,[R,a(e)]),n(" 命令监听指定的 Key，当调用 "),_,n(" 命令执行事务时，如果一个被 "),E,n(" 命令监视的 Key 被 "),x,n(" 修改的话，整个事务都不会被执行。")]),T,s("p",null,[n("不过，如果 "),O,n(" 与 "),q,n(" 在同一个 Session 里，并且被 "),S,n(" 监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功的（相关 issue："),s("a",C,[n("WATCH 命令碰到 MULTI 命令时的不同效果"),a(e)]),n("）。")]),w,s("p",null,[n("Redis 官网相关介绍 "),s("a",L,[n("https://redis.io/topics/transactions"),a(e)]),n(" 如下：")]),G,s("ul",null,[s("li",null,[s("a",N,[n("issue#452: 关于 Redis 事务不满足原子性的问题"),a(e)]),n(" 。")]),s("li",null,[s("a",A,[n("Issue#491:关于 Redis 没有事务回滚？"),a(e)])])]),j,s("p",null,[n("另外，Redis 7.0 新增了 "),s("a",K,[n("Redis functions"),a(e)]),n(" 特性，你可以将 Redis functions 看作是比 Lua 更强大的脚本。")]),I,U,s("ul",null,[s("li",null,[s("a",J,[n("你的 Redis 真的变慢了吗？性能优化如何做 - 阿里开发者"),a(e)])]),s("li",null,[s("a",M,[n("Redis 常见阻塞原因总结 - JavaGuide"),a(e)])])]),D,s("p",null,[n("另外，除了能减少 RTT 之外，发送一次命令的 socket I/O 成本也比较高（涉及上下文切换，存在"),P,n("和"),z,n("系统调用），批量操作还可以减少 socket I/O 成本。这个在官方对 pipeline 的介绍中有提到："),s("a",B,[n("https://redis.io/docs/manual/pipelining/"),a(e)]),n(" 。")]),F,s("blockquote",null,[W,s("p",null,[n("我在 "),s("a",H,[n("Redis 集群详解（付费）"),a(e)]),n(" 这篇文章中详细介绍了 Redis Cluster 这部分的内容，感兴趣地可以看看。")])]),Q,s("ul",null,[s("li",null,[s("a",Y,[n("redis-rdb-tools"),a(e)]),n("：Python 语言写的用来分析 Redis 的 RDB 快照文件用的工具")]),s("li",null,[s("a",V,[n("rdb_bigkeys"),a(e)]),n(" : Go 语言写的用来分析 Redis 的 RDB 快照文件用的工具，性能更好。")])]),X,Z,s("p",null,[n("这里以阿里云 Redis 为例说明，它支持 bigkey 实时分析、发现，文档地址："),s("a",$,[n("https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature"),a(e)]),n(" 。")]),ss,s("p",null,[n("京东零售的 "),s("a",ns,[n("hotkey"),a(e)]),n(" 这个项目不光支持 hotkey 的发现，还支持 hotkey 的处理。")]),es,as,is,ts,os,ls,rs,s("p",null,[n("这里以阿里云 Redis 为例说明，它支持 hotkey 实时分析、发现，文档地址："),s("a",ps,[n("https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature"),a(e)]),n(" 。")]),ds,s("p",null,[cs,n("："),s("a",us,[n("Redis 内存碎片详解"),a(e)]),n("。")]),hs,s("p",null,[n("更多关于布隆过滤器的内容可以看我的这篇原创："),s("a",ms,[n("《不了解布隆过滤器？一文给你整的明明白白！》"),a(e)]),n(" ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了。")]),ks,s("p",null,[n("相关文章推荐："),s("a",bs,[n("缓存和数据库一致性问题，看这篇就够了 - 水滴与银弹"),a(e)]),n("。")]),gs,s("p",null,[n("单独抽了一篇文章来总结可能会导致 Redis 阻塞的情况："),s("a",vs,[n("Redis 常见阻塞原因总结"),a(e)]),n("。")]),ys,s("p",null,[fs,n("："),s("a",Rs,[n("Redis 集群详解（付费）"),a(e)]),n("。")]),_s,s("p",null,[n("相关文章推荐："),s("a",Es,[n("阿里云 Redis 开发规范"),a(e)]),n(" 。")]),xs,s("ul",null,[Ts,Os,s("li",null,[n("Redis Transactions : "),s("a",qs,[n("https://redis.io/docs/manual/transactions/"),a(e)])]),s("li",null,[n("What is Redis Pipeline："),s("a",Ss,[n("https://buildatscale.tech/what-is-redis-pipeline/"),a(e)])]),s("li",null,[n("一文详解 Redis 中 BigKey、HotKey 的发现与处理："),s("a",Cs,[n("https://mp.weixin.qq.com/s/FPYE1B839_8Yk1-YSiW-1Q"),a(e)])]),s("li",null,[n("Redis延迟问题全面排障指南："),s("a",ws,[n("https://mp.weixin.qq.com/s/mIc6a9mfEGdaNDD3MmfFsg"),a(e)])])])])}const Ks=t(p,[["render",Ls],["__file","redis-questions-02.html.vue"]]);export{Ks as default};
